{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a49a1546-a3b8-40c7-b398-58bd3c993bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6ebc8d6-7dd0-4dfc-8375-1fe276496bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from morphert.model import *\n",
    "from tqdm.auto import tqdm\n",
    "from opencc import OpenCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "652f43ab-f0d3-496d-b5bd-79cd3962d0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2s = OpenCC('t2s').convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d856d1b0-fc86-4495-a83e-bfd9c44402de",
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = np.load(\"../data/ham_seq_768_1k.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d92b18c2-618d-4fbe-8ab4-674985b4a1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word</th>\n",
       "      <th>lexicality</th>\n",
       "      <th>N</th>\n",
       "      <th>RT</th>\n",
       "      <th>RTSD</th>\n",
       "      <th>zRT</th>\n",
       "      <th>zRTSD</th>\n",
       "      <th>ERR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>200001</td>\n",
       "      <td>一切</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>610.620250</td>\n",
       "      <td>104.615792</td>\n",
       "      <td>-0.744272</td>\n",
       "      <td>0.294925</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>200002</td>\n",
       "      <td>一共</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>741.714250</td>\n",
       "      <td>248.347155</td>\n",
       "      <td>-0.309554</td>\n",
       "      <td>0.739127</td>\n",
       "      <td>4.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>200003</td>\n",
       "      <td>一律</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>736.614615</td>\n",
       "      <td>147.969630</td>\n",
       "      <td>-0.409607</td>\n",
       "      <td>0.445567</td>\n",
       "      <td>7.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>200004</td>\n",
       "      <td>一样</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>700.449500</td>\n",
       "      <td>296.422704</td>\n",
       "      <td>-0.484063</td>\n",
       "      <td>0.820917</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>200005</td>\n",
       "      <td>一般</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>618.666250</td>\n",
       "      <td>139.388386</td>\n",
       "      <td>-0.691929</td>\n",
       "      <td>0.478496</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id word  lexicality   N          RT        RTSD       zRT     zRTSD  \\\n",
       "2040  200001   一切           1  40  610.620250  104.615792 -0.744272  0.294925   \n",
       "2041  200002   一共           1  40  741.714250  248.347155 -0.309554  0.739127   \n",
       "2042  200003   一律           1  39  736.614615  147.969630 -0.409607  0.445567   \n",
       "2043  200004   一样           1  40  700.449500  296.422704 -0.484063  0.820917   \n",
       "2044  200005   一般           1  40  618.666250  139.388386 -0.691929  0.478496   \n",
       "\n",
       "           ERR  \n",
       "2040  0.000000  \n",
       "2041  4.761905  \n",
       "2042  7.142857  \n",
       "2043  0.000000  \n",
       "2044  0.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"../data/Tsang-2018-MELD-SCH.xlsx\", sheet_name=0)\n",
    "bisyll_items = data.loc[data.length==2, :]\n",
    "bisyll_wd = bisyll_items.loc[data.lexicality==1, :]\n",
    "bisyll_wd = bisyll_wd[[\"id\", \"word\", \"lexicality\", \"N\", \"RT\", \"RTSD\", \"zRT\", \"zRTSD\", \"ERR\"]]\n",
    "bisyll_wd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e9d0e2c-bbb2-4ee8-92b8-31599c97880d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10022, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bisyll_wd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33ae73c4-271c-4cb3-8426-45f6a0f8b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../data\"\n",
    "with open(base_dir + \"/tencent_small_500k.pkl\", \"rb\") as fin:\n",
    "    (vocabs, embs) = pickle.load(fin)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "befc7572-b0a7-477a-b7f5-aa9492852624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "261cfc53-47a7-4353-be08-07776145263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500000\n",
    "base_dir = \"../data\"\n",
    "with open(base_dir + \"/tencent_small_500k.pkl\", \"rb\") as fin:\n",
    "    (vocabs, embs) = pickle.load(fin)   \n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "model = MorphertModel.from_pretrained(base_dir + \"/morphert_500k\")\n",
    "collator_fn = DataCollator(tokenizer)\n",
    "model = model.to(\"cuda\")\n",
    "full_ds = MorphertDataset(np.arange(N), vocabs, embs)\n",
    "full_emb = np.vstack([full_ds[i][\"vec\"] for i in range(N)])\n",
    "in_tencent = lambda x: x in full_ds.vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da92070b-9db9-4775-8853-0327cc6ef6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7442, 5582, 102], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"電腦\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "356e7c3d-3110-4312-b951-c0c17cd0ba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_embeds = model.bert.embeddings.word_embeddings(torch.tensor([[101, 7442, 5582, 102]]).to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da22ecc6-1a66-4321-92c8-7bb5fe257587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df47039b-7fc2-4fcf-bd4d-f2241edc5278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_embeds = model(inputs_embeds=in_embeds)\n",
    "out_tokens = model(**tokenizer(\"電腦\", return_tensors=\"pt\").to(\"cuda\"))\n",
    "torch.allclose(out_embeds.predictions, out_tokens.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcea3012-3516-40d9-a284-a28fdf23a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd.functional import jacobian\n",
    "def compute_token_jacobian(tgt_word, tgt_loc, model, tokenizer):\n",
    "    tgt_loc += 1  # offset the [CLS] token\n",
    "    assert 1 <= tgt_loc <= len(tgt_word)\n",
    "    tokens = tokenizer([tgt_word], return_tensors=\"pt\").to(\"cuda\")\n",
    "    in_embeds = model.bert.embeddings.word_embeddings(tokens.input_ids)\n",
    "    def partial_effect(x):        \n",
    "        in_embeds[:,tgt_loc,:] = x\n",
    "        out = model(inputs_embeds=in_embeds)\n",
    "        return out.predictions\n",
    "    J = jacobian(partial_effect, in_embeds[:,tgt_loc,:])\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91759054-b1fa-4c47-9810-bce84d267f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'电'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2s(\"電\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a5a5237-73ac-4aa7-baac-97a075284a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_set = [x for x in vocabs if len(x)==2 and x[0] in \"電电\"]\n",
    "c2_set = [x for x in vocabs if len(x)==2 and x[1] in \"電电\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4038ede5-b0f5-4dbd-8d36-207fe7e4db38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c1_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f67fa4bd-2e6a-4f84-b5d1-023a1a4e628b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7f8e3397c648c0995f565ec9101571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Js = []\n",
    "for word in tqdm(c1_set):\n",
    "    J = compute_token_jacobian(word, 0, model, tokenizer).squeeze().cpu().numpy()\n",
    "    Js.append(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23816e06-59e3-4ca5-adb9-9ac2d136040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "from itertools import  combinations\n",
    "distJ = np.zeros((len(Js), len(Js)))\n",
    "for i, j in combinations(range(len(Js)), 2):\n",
    "    L1norm = np.abs(Js[i] - Js[j]).sum()\n",
    "    distJ[i,j] = distJ[j,i] = L1norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0b72bd6-d15c-4e05-90f1-5fd7a07bf7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 157)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distJ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "041d1a62-7250-478e-8d78-8a6dc4ade3dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Numba needs NumPy 1.21 or less",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mumap\u001b[39;00m\n\u001b[0;32m      2\u001b[0m umap_inst \u001b[38;5;241m=\u001b[39m umap\u001b[38;5;241m.\u001b[39mUMAP()\n\u001b[0;32m      3\u001b[0m proj \u001b[38;5;241m=\u001b[39m umap_inst\u001b[38;5;241m.\u001b[39mfit_transform(distJ, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomuted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\umap\\__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn, catch_warnings, simplefilter\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mumap_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UMAP\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m catch_warnings():\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\umap\\umap_.py:28\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tril \u001b[38;5;28;01mas\u001b[39;00m sparse_tril, triu \u001b[38;5;28;01mas\u001b[39;00m sparse_triu\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcsgraph\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mumap\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistances\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdist\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mumap\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msparse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\numba\\__init__.py:200\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    199\u001b[0m _ensure_llvm()\n\u001b[1;32m--> 200\u001b[0m \u001b[43m_ensure_critical_deps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m# we know llvmlite is working as the above tests passed, import it now as SVML\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# needs to mutate runtime options (sets the `-vector-library`).\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mllvmlite\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\numba\\__init__.py:140\u001b[0m, in \u001b[0;36m_ensure_critical_deps\u001b[1;34m()\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumba needs NumPy 1.18 or greater\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m numpy_version \u001b[38;5;241m>\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m21\u001b[39m):\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumba needs NumPy 1.21 or less\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Numba needs NumPy 1.21 or less"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "umap_inst = umap.UMAP()\n",
    "proj = umap_inst.fit_transform(distJ, metric=\"precomuted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95233311-ec3f-44ce-8dd7-85305e7f73fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(proj[:,0],proj[:,1], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d8f497-3573-4d51-99e0-f79fad242458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
